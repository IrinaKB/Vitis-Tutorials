<table>
 <tr>
   <td align="center"><img src="https://japan.xilinx.com/content/dam/xilinx/imgs/press/media-kits/corporate/xilinx-logo.png" width="30%"/><h1>2019.2 Vitis™ アプリケーション アクセラレーション開発フローのチュートリアル</h1><a href="https://github.com/Xilinx/SDAccel-Tutorials/branches/all">SDAccel™ 開発環境 2019.1 チュートリアルを参照</a></td>
 </tr>
 <tr>
 <td align="center"><h1>アクセラレーション FPGA アプリケーションの最適化: ブルーム フィルターの例</td>
 </tr>
</table>

# 1\. 元のアプリケーションの評価

## アプリケーション

ドキュメント フィルターとは、システムにより、入力ドキュメントのストリームが監視され、内容に基づいて分類され、特定ユーザーまたはトピックに関連していると判断されたドキュメントが選択されるプロセスです。ビッグデータがますます中心的な役割を果たすようになっている世界では、無関係の情報をフィルターではじき、関連情報を意味のあるカテゴリーに分類する機能が重要です。ドキュメント フィルターは、ユーザーが関心を持っているドキュメントを特定しやすくする目的で、日々の検索や、情報の獲得や解析において広く利用されています。

現実的に考えると、1 つのイベントで検索されるドキュメントの数は非常に多く、また、イベントはリアルタイムで管理する必要があるので、より短い実行時間ですべてのドキュメントを処理する必要があります。このチュートリアルでは、ドキュメントの関連性を表すスコアをドキュメントごとに計算します。このアプリケーションのパフォーマンスは、データベース内のすべてのドキュメントを処理する実行時間およびスループットで計測されます。

ユーザーの関心度は検索配列で表されます。この配列には、ユーザーが関心を持っているワードと、それに関連付けられる重みが含まれます。この重みは、ユーザーの関心度に基づいてそのワードがどれくらい重要なのかを示します。したがって、ドキュメントの入力ストリームを監視しながら、データベースに格納されているワードに関連付けられている重みを検索する必要があります。ネイティブ インプリメンテーションでは、ワードがデータベース内にあるかどうかをチェックするために、ドキュメント内のあらゆるワードがデータベースで照会され、もしワードがデータベースにあった場合は、そのワードの重みが検索されます。このプロセスをさらに最適化するのであれば、キャッシュに空間効率のよいブルーム フィルターを使用します。これならデータベースにワードがあったかどうかの結果をレポートできるので、コストのかかるデータベース照会回数を減らすことができます。

ブルーム フィルターはハッシュテーブルベースのデータ構造で、データセットにエレメントがあるかどうかをテストするのに使用できます。フォルス ポジティブの一致はあっても、フォルス ネガティブはありません。つまり、データベースを照会すると、「possibly in set (セット内にある可能性がある)」、または「definitely not in set (絶対にセット内にはない)」が返されます。ブルーム フィルターを使用する利点は、空間効率がよいことと、データベースにないデータの照会回数が劇的に減る点です。また、ブルーム フィルターは、検索エンジンや、Cassandra や Postgres などのデータベース管理システムをインプリメントするためのアプリケーションでも有用で、照会回数を減らすことができるので、パフォーマンスが向上します。

フォルス ポジティブ率 (ブルーム フィルターが間違って、データベース内にデータがあるかもしれないとレポートする件数) は、1% 未満 (セット内のエレメントのサイズや数にかかわらず、エレメントごとに 10 ビット未満) に下げることが可能です。

必要なフォルス ポジティブ率によりますが、ハッシュ関数の数 (セット内のエレメント数およびブルーム フィルター内のビット数) は調整可能です。

次の図は、セット {x, y, z} を表すブルーム フィルターの例です。色分けされた矢印は、各セット エレメントがマップされているビット配列の位置を示しています。エレメント「w」は、0 を含む 1 ビット配列位置にハッシュしているので、セット {x, y, z} にはありません。次の図では、エレメント数は 18 で、各エレメントに対し計算されるハッシュ関数の数は 3 になっています。

![](./images/bloom.PNG)

## インプリメンテーション

この例では、各ドキュメントがワードの配列で構成されていて、各ワードは 32 ビットの符号なし整数 (24 ビットのワード ID と頻度を表す 8 ビット) です。検索配列はユーザーが関心を持っているワードで構成されています。こちらは小さくて、24 ビットのワード ID のセットです。各ワード ID にはワードに関連付けられている重みがあり、それがワードの重要性を判断します。`bloom` ディレクトリに移動してから `cpu_src` ディレクトリに移動し、`main.cpp` ファイルの 65 行目を確認すると、ブルーム フィルターのサイズが 64 KB であることがわかります。これは、`1L<<bloom_size` としてインプリメントされていて、ヘッダー ファイル `sizes.h` では `bloom_size` が 14 に定義されているので、(2\^14)\*4B = 64 KB になります。

各ドキュメントのスコアは、ワード ID の重みとそのワードの頻度を掛け合わせた累積積によって算出されます。スコアが大きければ大きいほど、検索配列と一致しているドキュメントの関連例が高いということになります。

例:

* **検索配列**: \[{word\_1,10},{word\_3,20},{word\_6,30}]
* **ドキュメント**: \[{word\_1,20} ,{word\_2,40},{word\_3,50}]
* **ドキュメントのスコア計算**: 20x10 + 0x40 + 50x20 = 1200

次の手順では、元のアクセラレートされていないアプリケーションのベースライン パフォーマンス データを作成するために、このアプリケーションをビルドして実行します。

## C アプリケーションのビルド

`cpu_src` ディレクトリに移動し、**make** を実行して、実行ファイルを生成します。

このコマンドを実行すると、C ソース コードがコンパイルされ、`host` 実行ファイルがビルドされます。この実行ファイルには、ドキュメント数を入力引数に指定する必要があります。

> **ヒント**: この演習で使用される `Makefile` には、ステップや変数といった詳細情報が含まれています。Makefile の構造および内容については、[Makefile について](./HowToRunTutorial.md)を参照してください。

## C アプリケーションの実行およびゴールデン結果の生成

この手順では、次のコマンドを使用して、元の C アプリケーションに引数としてドキュメント数を指定して実行し、比較目的でゴールデン出力ファイルを生成します。

```
cd bloom/design/cpu_src/build
./host cpu 100000
```

生成された出力スコアはホスト コードの `cpu_profile_score` 配列に格納されます。このスコアは指定されたドキュメント総数の出力を表します。

## アプリケーションのプロファイリング

アクセラレートするのは `runOnCPU` 関数だけなので、実行ファイルを実行し、この関数の実行時間を評価します。

1. プロファイル結果を抽出します。

   ```
   gprof host gmon.out> gprofresult.txt
   ```

2. プロファイル サマリ レポートを確認するため、テキスト エディターで `gprofresult.txt` ファイルを開きます。次の表のような結果が確認できるはずです。

   各サンプルは 0.01 秒としてカウントします。

   個々のサブ関数のフラットなプロファイル レポートは次のようになります。

   > **注記:** パフォーマンス プロファイルは、使用しているコンピューターおよびそのコンピューターの負荷によって変わります。

   | % 時間| 累積秒数| 秒数 (セルフ)| 合計呼び出し数| ms/呼び出し| ms/呼び出し| 名前
   |----------:|----------:|----------:|----------:|----------:|----------:|:----------
   | 48.06| 8.76| 8.76| 802078720| 0.00| 0.00| MurmurHash2
   | 24.93| 13.30| 4.54| 1| 4.54| 13.30| runOnCPU
   | 21.14| 17.15| 3.85| 1| 2.85| 4.88| setupData

   アプリケーションが各ドキュメントのワードのハッシュ値を計算するサブ関数 `MurmurHash2` にほぼ半分の時間を費やしているのがわかります。`MurmurHash2` サブ関数は `main` 関数の一部として `runOnCPU` および `setupData` 関数により読み出されます。

   次の表は、前のレポート `gprofresults.txt` のコールグラフの一部として `main` 関数内のこれらの関数の概要を示しています。

   | % 時間| セルフ| 子| 呼び出された回数| 名前
   |----------:|----------:|----------:|----------:|:----------
   | 72.9| 4.54| 8.76| 1| runOnCPU
   | 26.8| 3.85| 1.03| 1| setupData

   `main` 関数の観点から見ると、CPU はほぼ 73% の時間を `runOnCPU` 関数に費やしています。`runOnCPU` 関数には、子呼び出しは 1 つしかありません (`MurmurHash2` 関数)。表の実行時間に基づいて、`MurmurHash2` への呼び出しによって費やされた時間は約 66% **((8.76/(8.76+4.54))** だと推測できます。したがって、`runOnCPU` 関数を高速化すると、このアプリケーションのパフォーマンスが大幅に向上します。

## 達成可能な最大スループットの判断

ほとんどの FPGA アクセラレーション システムにおいて、達成可能な最大スループットは PCIe® バスの制限を受けます。PCIe のパフォーマンスは、マザーボード、ドライバー、ターゲット シェル、転送サイズなど、さまざまな要因に影響されます。Vitis コア開発キットには `xbutil` というユーティリティがあり、`xbutil dmatest` コマンドを実行して、達成可能な最大の PCIe 帯域を計測できます。ターゲットのスループットがこの上限を超えることはできません。

## 全体的なアクセラレーション目標の設定

このチュートリアルでは 100,000 個のドキュメント (1.6 GB) を処理するのが目標です。CPU では、100 個のドキュメントの処理に 11.22 ms かかります。各ドキュメントには、平均して約 3500 ワード (符号なしの整数) があります。つまり、約 **(3500\*100)\*4B/11.2 ms = 124.78 MB/s** のスループットを達成しようとしています。目標は 100,000 個のドキュメント (1.6 GB) を処理することですから、100,000 個のドキュメントにホスト コード実行すると、その実行時間は 11.74 s になります。

実行時間が 1 秒未満であればドキュメントのスコアを計算できるはずなので、アプリケーションのスループットを改善する必要があります。この目標を念頭に置いて、まずはこの目標が FPGA で達成可能かどうかを確認します。100,000 個のドキュメント処理に実行時間が 0.6 秒かかる場合は、1.6 GB 分のドキュメントを処理するので必要なスループットは 2.67 GB/s です。まずは、このスループットがカーネルで達成可能な最大値未満であるかどうかを確認し、さらに、このスループット目標が Alveo データセンター アクセラレータ カードの達成可能な最大スループットの範囲内かどうかを確認します。

[Vitis 統合ソフトウェア プラットフォームを使用したアプリケーションのアクセラレーション手法](https://japan.xilinx.com/html_docs/xilinx2019_2/vitis_doc/Chunk1821279816.html#wgb1568690490380)の[手順 3: デバイス並行処理のニーズの特定](https://japan.xilinx.com/html_docs/xilinx2019_2/vitis_doc/Chunk1821279816.html#kjk1555544737506)で説明されているように、カーネルからの達成可能な最大スループットは次のように概算されます。

**Thw \= (周波数 / 計算負荷) = (周波数 \* max(VINPUT, VOUTPUT) / VVOPS)**

説明:

* **VINPUT**、**VOUTPUT**: 処理された入力および出力データ量を表します。
* **VOPS**: 入力および出力データで処理された演算数を表します。
* 関数の**計算負荷**: 入力データおよび出力データの最大量に対する演算の総数の比です。  このアプリケーションでは、処理された入力データ量が生成された出力データ量を超えています (ドキュメント スコアはドキュメントごとにしか計算されないので)。各入力ワードは、ドキュメント スコアの計算に 1 回しか使用されていないので、計算負荷は 1 です。

**Thw = (周波数 \* 1) サンプル数**

各サンプルは 4 バイトのデータなので、カーネルの最大スループットは **Thw = (300MHz) \* 4B = 1.2GB/s** です。

コード内の並列処理を解析すると、各ドキュメントの演算スコアはほかのドキュメントの影響は受けていません。各ドキュメント内の演算には 2 段階あり、1 つは各ドキュメントのハッシュ関数の計算、もう 1 つはハッシュ値に基づいたドキュメント スコアの計算です。1 段階目のハッシュ関数の計算は各ワードを並列処理して実行されます。2 段階目では、この第 1 段階で計算されたハッシュ値に基づいてワードの値を減らします。

さらに多くのワードを並列処理できるように、CU のデータパスを広げ、CU をさらに強化して、並列処理を達成する方法が 1 つ考えられます。また、複数のドキュメントのスコアを並列計算するために CU のデータパスを広げるのではなく、CU を置き換える方法もあります。最善の結果を得るには、いずれかのアプローチを利用するか、または両方の利点を合わせたハイブリッド アプローチを利用してください。このチュートリアルでは、コード記述が簡単という理由から、CU を置き換えるアプローチを取ります。これでスループット目標を達成できます。

ターゲットのスループットは 2.67 Gb/s なので、CU を置き換えて必要なスループットを達成できます。このチュートリアルの後で実行する最適化で、外部メモリが停止し、カーネルでは達成可能な最大スループットにできなくなります。このため、CU の数は 4 に据え置きます。CU を置き換える場合は、CU を増やせばリソース数も増えるので注意が必要です。リソース使用率が FPGA 上のリソース数を超えると、デザインを FPGA で構築できません。1 つの CU を実行した後、デバイスにフィット可能な CU の最大数を見積もっておく必要があります。

スループット目標も、Alveo データセンター アクセラレータ カードの PCIe インターフェイスで達成可能なスループットの範囲内にします。このチュートリアルでは、この目標を達成する方法を説明します。

## 次のステップ

アクセラレーションのターゲットである元のアプリケーションの関数を特定し、パフォーマンス目標を確立しました。次の演習では、ハードウェアで実行する元のブルーム フィルター機能のベースラインを作成し、パフォーマンス目標を満たすため、ホストおよびカーネル コードを最適化します。まずは、元のアプリケーションから [Vitis コア開発キット アプリケーションを作成](./baseline_fpga.md)するところから始めます。

また、各ステップでパフォーマンスを計測するため、ハードウェア エミュレーション run を使用します。最終ステップでは、各ステップでどのようにパフォーマンスが改善されたかを確認するため、ハードウェアでこれらのステップをすべて実行できます。</br>

<hr/>
<p align="center"><b><a href="../../docs/vitis-getting-started/README.md">入門ガイドの最初に戻る</a> &mdash; <a href="./README.md">チュートリアルの最初に戻る</a></b></p>
<p align="center"><sup>Copyright&copy; 2019 Xilinx</sup></p>

<table>
 <tr>
   <td align="center"><img src="https://japan.xilinx.com/content/dam/xilinx/imgs/press/media-kits/corporate/xilinx-logo.png" width="30%"/><h1>2019.2 Vitis™ アプリケーション アクセラレーション開発フローのチュートリアル</h1><a href="https://github.com/Xilinx/SDAccel-Tutorials/branches/all">SDAccel™ 開発環境 2019.1 チュートリアルを参照</a></td>
 </tr>
 <tr>
 <td align="center"><h1>アクセラレーション FPGA アプリケーションの最適化: ブルーム フィルターの例</td>
 </tr>
</table>

# 7\. ハードウェアでのアクセラレータの実行

ここまでは、システムをビルドするのに必要なコンパイル時間を短縮しつつ、最適化によりパフォーマンスをどのように改善できるかを理解するため、これまでのすべての演習はハードウェア エミュレーション モードで実行してきました。このセクションでは、ここまでの演習で説明してきたハードウェアでの最適化を、Alveo データセンター アクセラレータ カード上でビルドして実行します。

各実行を完了したら、タイムライン トレース レポートからのパフォーマンス データを記録し、このセクションの最後にある表にそれを記入します。実際に書き込む数値は例とは異なる場合があります。  
次のデータに注意してください。

* **合計データ**: (**ドキュメント総数 x ドキュメント サイズ**) で計算されます。

* **合計時間**: C++ タイマーで CPU の時間を計測します。

  公正な比較ができるように、データ転送およびカーネル実行の時間がこれに含まれます。

* **スループット**: **処理されたデータ合計 (MB)/合計時間**で計算されます。

> **重要**: この演習の各ステップで毎回ハードウェア カーネルがコンパイルされるので、完了するまでにはかなり時間がかかる可能性があります。

## ハードウェアでのベースライン アプリケーションの実行

次のコマンドを使用して、ハードウェアで実行し、タイムライン トレース レポートを生成および確認します。

```
make run TARGET=hw STEP=baseline NUM_DOCS=100000
```

## ハードウェアでのメモリ転送の実行

次のコマンドを使用して、ハードウェアで実行し、タイムライン トレース レポートを生成および確認します。

```
make run TARGET=hw STEP=localbuf  NUM_DOCS=100000
```

## ハードウェアでの複数演算ユニットの実行

次のコマンドを使用して、ハードウェアで実行し、タイムライン トレース レポートを生成および確認します。

```
make run TARGET=hw STEP=multicu  NUM_DOCS=100000
```

## ハードウェアでの複数 DDR バンクの実行

次のコマンドを使用して、ハードウェアで実行し、タイムライン トレース レポートを生成および確認します。

```
make run TARGET=hw STEP=multiddr  NUM_DOCS=100000
```

### パフォーマンス表

最終的なパフォーマンスのベンチマーキング表は次のように表示されます。

| 演習                            | Number of Documents   | Average Document Size (kB) | Number of Compute Units | Time (Hardware) (s) | Throughput (MBps) |
| :-----------------------        | :----------- | ------------: | ----------------:| ------------------: | ----------------: |
| CPU                       |     100000 |           16 |     - |          11.45 |     139.73 (1xCPU)       |
| baseline_fpga                   |     100000 |           16 |   1 |            113.12 |     12.38 (0.09xCPU)          |
| localbuf                        |     100000|           16 |    1 |           2.40  |   666.67 (4.77xCPU)      |
| dataflow                       |     100000|           16 |      1 |          2.35  |   680.85 (4.87xCPU)      |
| multi-CU                        |     100000 |           16 |     2 |            0.95 |    1636.82.05xCPU)   |
| multi-DDR                        |     100000 |           16 |      4 |           0.62 |    2587.24(18.5xCPU)   |
---------------------------------------

> **注記**: ランタイムは実行ごとに異なる可能性があります。

なぜ各ステップがパフォーマンスの改善に役立ったのかを理解することが重要です。

* グローバル メモリからローカル メモリに `bloom filter` 配列をコピーすると、グローバル メモリにアクセスするときのレイテンシが低減され、パフォーマンスが改善されます。
* ループの最初のインターバル (II) でデータフローを使用しても、II は既に 1 なので、あまりパフォーマンスは改善されません。
* ドキュメントを並行処理しているので演算ユニット (CU) を置き換えるとパフォーマンスが改善します。
* CU が 4 つある DDR バンクを複数使用すると、CU のおかげで DDR ポートでの競合が低減されるので、パフォーマンスが改善します。

## まとめ

これでこの演習のすべてのモジュールを終了しました。標準 CPU ベースのアプリケーションを FPGA でアクセラレートされるアプリケーションに変換し、Alveo データセンター U200 アクセラレータ カード上でそれを実行して、CPU の約 19 倍のスループットで実行しました。パフォーマンスの目標を設定し、その目標を達成するために、さまざまな最適化を実行しました。

1. C アプリケーションから Vitis コア開発キット アプリケーションを作成しました。
2. ソフトウェアおよびハードウェア エミュレーション中に生成されたレポートについて学びました。
3. HLS カーネルのさまざまな最適化方法を学びました。
4. パフォーマンスを改善する目的でアウト オブ オーダー キューを利用し、Open CL API コマンド キューを設定する方法を学びました。
5. 複数の演算ユニットで実行するためカーネルをイネーブルにしました。
6. 複数の DDR バンクで実行するためカーネルをイネーブルにしました。
7. 実際にパフォーマンスが改善されたことを確認するため、Alveo データセンター アクセラレータ カード上で最適化されたアプリケーションを実行しました。</br>

<hr/>
<p align= center><b><a href="../../docs/vitis-getting-started/README.md">入門ガイドの最初に戻る</a> &mdash; <a href="./README.md">チュートリアルの最初に戻る</a></b></p></br><p align="center"><sup>Copyright&copy; 2019 Xilinx</sup></p>
